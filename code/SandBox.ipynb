{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json # original json library\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import sklearn\n",
    "import shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILENAME = '/home/benjamin/Folders_Python/Cyber/logs/logfile.log'\n",
    "LOG_FORMAT = '%(asctime)% -- %(name)s -- %(levelname)s -- %(message)s'\n",
    "# LOG_LEVEL = logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific logger for the module\n",
    "logger = logging.getLogger(__name__)   # creates specific logger for the module\n",
    "logger.setLevel(logging.DEBUG)    # entry level of messages from all handlers\n",
    "LOG_FORMAT = '%(asctime)s -- %(name)s -- %(levelname)s -- %(message)s'\n",
    "formatter = logging.Formatter(LOG_FORMAT)\n",
    "\n",
    "# file handler to log everything\n",
    "file_handler = logging.FileHandler(LOG_FILENAME, mode='w')\n",
    "file_handler.setLevel(logging.INFO)  # all messages (DEBUG and up) get logged in the file\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# stream handler to show messages to the console\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.WARNING)  # Warning messages and up get displayed to the console\n",
    "console.setFormatter(formatter)\n",
    "logger.addHandler(console)\n",
    "\n",
    "# start your engine\n",
    "logger.info(\"-------- new run --------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pcap file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB : tshark -r <file>.pcap -T json > <file_pcap>.json -t r\n",
    "# commande shell qui prend un pcap et le passe en json\n",
    "\n",
    "!rm /home/benjamin/Folders_Python/Cyber/data/outputs/input_pcap.json\n",
    "!tshark -r /home/benjamin/Folders_Python/Cyber/data/input_pcaps/input.pcap -T json -t r > /home/benjamin/Folders_Python/Cyber/data/outputs/input_pcap.json\n",
    "\n",
    "logger.info(\"run tshark to create json translation of input.pcap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Packet():\n",
    "    \"\"\"Utility self-made unperfect class to parse the json object and extract features from a packet-like dict\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raw_packet:dict) -> None:\n",
    "        self.raw_packet = raw_packet\n",
    "        self._packet_data = None\n",
    "        # logger.debug('constructor of Packet instance has finished')\n",
    "        \n",
    "    @property\n",
    "    def packet_data(self):\n",
    "        # returns the full dictionnary of features\n",
    "        if self._packet_data is not None:\n",
    "            return self._packet_data\n",
    "        else:\n",
    "            sl = self.raw_packet.get('_source').get('layers')\n",
    "            slf = sl.get('frame')\n",
    "            sle = sl.get('eth')\n",
    "            sli = sl.get('ip', {})  # return empty dict as default not found value so it can handle another get method\n",
    "            slu = sl.get('udp', {})\n",
    "            slt = sl.get('tcp', {})\n",
    "                                               \n",
    "            self._packet_data = {\n",
    "                'frame_time' : slf.get('frame.time'),\n",
    "                'frame_time_relative' : slf.get('frame.time_relative'),\n",
    "                'frame_length' : slf.get(\"frame.len\"),\n",
    "                'frame_protocols' : slf.get(\"frame.protocols\"),\n",
    "                'eth_source': sle.get(\"eth.src\"),\n",
    "                'eth_dest': sle.get(\"eth.dst\") ,\n",
    "                'ip_version': sli.get(\"ip.version\"),\n",
    "                'ip_header_length': sli.get(\"ip.hdr_len\"),\n",
    "                'ip_length': sli.get(\"ip.len\"),\n",
    "                'ip_id': sli.get(\"ip.id\"),\n",
    "                'ip_flags': sli.get(\"ip.flags\"),\n",
    "                'ip_ttl': sli.get(\"ip.ttl\"),\n",
    "                'ip_proto': sli.get(\"ip.proto\"),\n",
    "                'ip_source': sli.get(\"ip.src\"),\n",
    "                'ip_dest': sli.get(\"ip.dst\"),\n",
    "                'udp_source_port': slu.get(\"udp.srcport\"),\n",
    "                'udp_dest_port': slu.get(\"udp.port\"),\n",
    "                'udp_length': slu.get(\"udp.length\"),\n",
    "                'tcp_source_port': slt.get(\"tcp.srcport\"),\n",
    "                'tcp_dest_port': slt.get(\"tcp.dstport\"),\n",
    "                'tcp_length': slt.get(\"tcp.len\"),\n",
    "                'tcp_flags': slt.get(\"tcp.flags\"),\n",
    "            }\n",
    "            # logger.debug('packet_data @property method has finished')\n",
    "            return self._packet_data\n",
    "        \n",
    "    @packet_data.setter\n",
    "    def packet_data(self, input):\n",
    "        \"\"\"illegal attempt to write packet_data\"\"\"\n",
    "        logger.warning('Illegal attempt to write a data_packet in a packet object')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAP_FILENAME = \"/home/benjamin/Folders_Python/Cyber/data/outputs/input_pcap.json\"\n",
    "\n",
    "with open (PCAP_FILENAME, errors='replace') as raw_packets:  # NB : errors='replace' bypasses decoding errors\n",
    "    json_object = json.load(raw_packets)    # load le fichier json dans une structure Python (list of dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple : premier dict de la liste : c'est un paquet (=une frame Ethernet)\n",
    "\n",
    "json_object[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple d'instanciation d'un objet Packet\n",
    "p = Packet(json_object[0])\n",
    "\n",
    "p.packet_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce DataFrame for Raw Packets analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créé la liste de dictionnaires des data des objets Packets\n",
    "packets = [ Packet(d).packet_data for d in json_object ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_packets = pd.DataFrame(packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_packets.describe(include='all').transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVE JSON Output by Suricata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Suricata to produce an eve.json file with alerts\n",
    "\n",
    "!rm /home/benjamin/Folders_Python/Cyber/data/outputs/eve.json\n",
    "!suricata -r /home/benjamin/Folders_Python/Cyber/data/input_pcaps/input.pcap -l /home/benjamin/Folders_Python/Cyber/data/outputs -k none\n",
    "\n",
    "logger.info(\"run Suricata to reassemble flows and create alert logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas provides a useful method – json_normalize – for normalizing nested JSON fields into dataframe. Resulting columns use dot notation to signify nested objects, similar to how Elasticsearch does it\n",
    "\n",
    "SURICATA_EVE_LOG = \"/home/benjamin/Folders_Python/Cyber/data/outputs/eve.json\"\n",
    "\n",
    "with open (SURICATA_EVE_LOG) as packets:\n",
    "    df_log = pd.json_normalize(\n",
    "        [json.loads(packet) for packet in packets],\n",
    "        max_level=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log[df_log['event_type']=='flow']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce DataFrame for Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Suricata doc :\n",
    "\n",
    "# 15.1.2.12. Event type: Flow\n",
    "# 15.1.2.12.1. Fields\n",
    "\n",
    "#     “pkts_toserver”: total number of packets to server, include bypassed packets\n",
    "#     “pkts_toclient”: total number of packets to client\n",
    "#     “bytes_toserver”: total bytes count to server\n",
    "#     “bytes_toclient”: total bytes count to client\n",
    "#     “bypassed.pkts_toserver”: number of bypassed packets to server\n",
    "#     “bypassed.pkts_toclient”: number of bypassed packets to client\n",
    "#     “bypassed.bytes_toserver”: bypassed bytes count to server\n",
    "#     “bypassed.bytes_toclient”: bypassed bytes count to client\n",
    "#     “start”: date of start of the flow\n",
    "#     “end”: date of end of flow (last seen packet)\n",
    "#     “age”: duration of the flow\n",
    "#     “bypass”: if the flow has been bypassed, it is set to “local” (internal bypass) or “capture”\n",
    "#     “state”: display state of the flow (include “new”, “established”, “closed”, “bypassed”)\n",
    "#     “reason”: mechanism that did trigger the end of the flow (include “timeout”, “forced” and “shutdown”)\n",
    "#     “alerted”: “true” or “false” depending if an alert has been seen on flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.stamus-networks.com/blog/jupyter-playbooks-for-suricata-part-1\n",
    "\n",
    "# https://malware-traffic-analysis.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow():\n",
    "    \"\"\"Utility class - takes a event-flow string out of eve.json,\n",
    "       creates a one-level dict structure, suitable for dataframe creation\n",
    "    \"\"\"\n",
    "    def __init__(self, flow_event:dict):\n",
    "        if flow_event.get('event_type') != 'flow':\n",
    "            logger.critical(\"Attempt to build a Flow instance with a non-flow event\")\n",
    "            raise ValueError\n",
    "        self._raw_flow_event = flow_event\n",
    "        self._features = None\n",
    "        \n",
    "    @property\n",
    "    def features(self):\n",
    "        if self._features is not None:\n",
    "            return self._features\n",
    "        else:\n",
    "            keys_list_first_level = [\n",
    "                'timestamp',\n",
    "                'flow_id',\n",
    "                'src_ip',\n",
    "                'src_port',\n",
    "                'dest_ip',\n",
    "                'dest_port',\n",
    "                'proto'\n",
    "            ]\n",
    "            keys_list_second_level = [\n",
    "                'pkts_toserver',\n",
    "                'pkts_toclient',\n",
    "                'bytes_toserver',\n",
    "                'bytes_toclient',\n",
    "                'start',\n",
    "                'end',\n",
    "                'age',\n",
    "                'state',\n",
    "                'reason',\n",
    "                'alerted'\n",
    "            ]\n",
    "            d1 = { k: self._raw_flow_event.get(k) for k in keys_list_first_level }\n",
    "            d2 = { k: self._raw_flow_event.get('flow').get(k) for k in keys_list_second_level }\n",
    "            self._features = { **d1, **d2 }\n",
    "            # logger.info(\"built a Flow features object\")\n",
    "            return self._features\n",
    "        \n",
    "    @features.setter\n",
    "    def features(self, input):\n",
    "        logger.critical(\"illegal attempt to hard write features in a Flow object\")\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return json.dumps(self.features, indent=4)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return json.dumps(self.features, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple de flow JSON = \n",
    "# {\n",
    "# \"timestamp\":\"2023-06-17T10:46:05.765744+0200\",\n",
    "# \"flow_id\":860724109937755,\n",
    "# \"event_type\":\"flow\",\n",
    "# \"src_ip\":\"2a01:cb19:872e:3000:0e4f:3187:540c:d66c\",\n",
    "# \"src_port\":47864,\n",
    "# \"dest_ip\":\"2a00:1450:4007:081a:0000:0000:0000:2003\",\n",
    "# \"dest_port\":80,\n",
    "# \"proto\":\"TCP\",\n",
    "# \"flow\":\n",
    "#     {\"pkts_toserver\":6,\n",
    "#     \"pkts_toclient\":5,\n",
    "#     \"bytes_toserver\":516,\n",
    "#     \"bytes_toclient\":430,\n",
    "#     \"start\":\"2023-06-17T10:46:10.625755+0200\",\n",
    "#     \"end\":\"2023-06-17T10:46:44.150502+0200\",\n",
    "#     \"age\":34,\n",
    "#     \"state\":\"new\",\n",
    "#     \"reason\":\"shutdown\",\n",
    "#     \"alerted\":true},\n",
    "# \"community_id\":\"1:uRhWV544zvWeIohZCmryZHXZ5EA=\",\n",
    "# \"tcp\":\n",
    "#     {\"tcp_flags\":\"00\",\n",
    "#     \"tcp_flags_ts\":\"00\",\n",
    "#     \"tcp_flags_tc\":\"00\"\n",
    "#     }\n",
    "# }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURICATA_EVE_LOG = \"/home/benjamin/Folders_Python/Cyber/data/outputs/eve.json\"\n",
    "\n",
    "i=0\n",
    "columns_names =  [\n",
    "                'timestamp',\n",
    "                'flow_id',\n",
    "                'src_ip',\n",
    "                'src_port',\n",
    "                'dest_ip',\n",
    "                'dest_port',\n",
    "                'proto'\n",
    "            ] + [\n",
    "                'pkts_toserver',\n",
    "                'pkts_toclient',\n",
    "                'bytes_toserver',\n",
    "                'bytes_toclient',\n",
    "                'start',\n",
    "                'end',\n",
    "                'age',\n",
    "                'state',\n",
    "                'reason',\n",
    "                'alerted'\n",
    "            ]\n",
    "dict_for_dataframe = { k:[] for k in columns_names }\n",
    "\n",
    "with open (SURICATA_EVE_LOG) as f:\n",
    "    for event_string in f:\n",
    "        python_object = json.loads(event_string)\n",
    "        if python_object.get('event_type')=='flow':\n",
    "            flow = Flow(python_object)\n",
    "            for k in columns_names:\n",
    "                if dict_for_dataframe[k] == []:\n",
    "                    dict_for_dataframe[k] = [flow.features.get(k)]\n",
    "                else:\n",
    "                    dict_for_dataframe[k].append(flow.features.get(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow = pd.DataFrame(data=dict_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_flow.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codage en ordinal\n",
    "\n",
    "df['src_ip_ord'], uniques_src_ip = pd.factorize(values=df['src_ip'])\n",
    "df['dest_ip_ord'], uniques_dest_ip = pd.factorize(values=df['dest_ip'])\n",
    "df['proto_ord'], uniques_proto = pd.factorize(values=df['proto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flows flagged as 'alerted' by Suricata\n",
    "\n",
    "df[df['alerted']==True]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['src_port', 'dest_port', 'pkts_toserver', 'pkts_toclient', 'bytes_toserver', 'bytes_toclient', 'age', 'src_ip_ord', 'dest_ip_ord', 'proto_ord', 'alerted']\n",
    "features_names = ['src_port', 'dest_port', 'pkts_toserver', 'pkts_toclient', 'bytes_toserver', 'bytes_toclient', 'age', 'src_ip_ord', 'dest_ip_ord', 'proto_ord']\n",
    "\n",
    "df_clean = df[columns_names].dropna()\n",
    "\n",
    "X = df_clean[features_names].to_numpy()\n",
    "y = df_clean['alerted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=.90)  # scikit learn trick : choose the number of components so that the explained variance is above 90%\n",
    "\n",
    "X_new = pca.fit_transform(X)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "xs = X_new[:,0]\n",
    "ys = X_new[:,1]\n",
    "zs = X_new[:,2]\n",
    "\n",
    "colors = [ 'red' if c == True else 'blue' for c in list(y)]\n",
    "\n",
    "ax.scatter3D(xs, ys, zs, c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = sklearn.svm.SVC(kernel='linear', probability=True)\n",
    "svc_linear.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_linear.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression of the eigen vectors in the features space\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.9, random_state=0)\n",
    "\n",
    "svc_linear = sklearn.svm.SVC(kernel='linear', probability=True)\n",
    "svc_linear.fit(X_train, Y_train)\n",
    "\n",
    "print(svc_linear.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "explainer = shap.KernelExplainer(svc_linear.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
