{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import *.pcap par tshark, labellisaton par Suricata, ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import collections\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# import ipywidgets\n",
    "# import warnings\n",
    "\n",
    "# import pyshark\n",
    "# import networkx as nx\n",
    "\n",
    "# from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.cluster import KMeans, DBSCAN\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.metrics import pairwise_distances, silhouette_score\n",
    "# from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "# import umap\n",
    "\n",
    "# from itertools import product\n",
    "\n",
    "# PATH change to access library cyberlib\n",
    "import sys\n",
    "sys.path.append('/home/benjamin/Folders_Python/Cyber/libs')\n",
    "import cyberlib as cbl\n",
    "\n",
    "# to allow PyShark to run in Jupyter notebooks\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging set-up\n",
    "\n",
    "lg = cbl.GetLogger('/home/benjamin/Folders_Python/Cyber/logs/pcap_labellisation.log')\n",
    "logger = lg.get_custom_logger()\n",
    "\n",
    "# start your engine\n",
    "logger.info(\"-------- new run --------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import *pcap by tshark, export to *.csv then DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which *.pcap\n",
    "DFNAME = 'smallFlows'  # file to translate to csv (NB : no *.pcap extension)\n",
    "\n",
    "DATA_INPUT = '/home/benjamin/Folders_Python/Cyber/data/input_pcaps/'\n",
    "PCAPFILE = '/home/benjamin/Folders_Python/Cyber/data/input_pcaps/' + DFNAME + '.pcap'\n",
    "\n",
    "DATA_OUTPUT = '/home/benjamin/Folders_Python/Cyber/data/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 ms, sys: 154 Âµs, total: 1.46 ms\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "# We use the tshark CLI to parse the *.pcap file and output a *.csv file for pandas\n",
    "# doc here : https://www.wireshark.org/docs/man-pages/tshark.html\n",
    "\n",
    "# for time exports : https://osqa-ask.wireshark.org/questions/30393/tshark-how-to-output-date-in-iso-format/\n",
    "# NB : outputs times in UTC to avoid time zone mismatches\n",
    "# -------> there is column 'Date' added in Wireshark preferences, with output in UTC day and time\n",
    "# -------> output -t ud requested in tshark : forces otuput in UTC\n",
    "\n",
    "# tshark :\n",
    "# -r                :   reads the *.pcap\n",
    "# -2, -R \"tcp\"      :   does 2 passes and keeps packets part of TCP conversations only\n",
    "# -T fields         :   outputs a file with fields\n",
    "# -E header=y       :   keeps the fields names on first row for pd.read_csv\n",
    "# -E separator=,    :   for *.csv format\n",
    "# -e <fields>       :   desired output fields\n",
    "# -o                :   formats of the data in the fields\n",
    "\n",
    "cli=\"tshark -r \" + PCAPFILE + \"\"\" -2 \\\n",
    "    -R \"tcp\" \\\n",
    "    -T fields -E header=y -E separator=, \\\n",
    "    -e _ws.col.Date -t ud \\\n",
    "    -e frame.number \\\n",
    "    -e eth.src -e eth.dst \\\n",
    "    -e ip.src_host -e ip.dst_host \\\n",
    "    -e ip.len -e ip.hdr_len -e ip.ttl \\\n",
    "    -e tcp.srcport -e tcp.dstport -e tcp.stream -e tcp.len \\\n",
    "    -e tcp.seq -e tcp.ack -e tcp.hdr_len -e tcp.time_relative \\\n",
    "    -e tcp.time_delta \\\n",
    "    -e tcp.flags \\\n",
    "    -o 'gui.column.format:\"No\",\"%m\",\"Date\",\"%t\",\"Source\",\"%s\",\"Destination\",\"%d\",\"Protocol\",\"%p\",\"Length\",\"%L\",\"Info\",\"%i\"' \\\n",
    "    > ~/Folders_Python/Cyber/data/input_pcaps/to_csv/output.csv\"\"\"\n",
    "\n",
    "%time exit_code = os.system(cli)\n",
    "\n",
    "if exit_code == 0:\n",
    "    logger.info('Executed successfully *.pcap to *.csv translation with tshark')\n",
    "else:\n",
    "    logger.error('Error while using tshark to translate from *.pcap to *.csv')\n",
    "    raise NameError('Error while using tshark to translate from *.pcap to *.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/benjamin/Folders_Python/Cyber/data/input_pcaps/to_csv/smallFlows.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = DATA_INPUT + 'to_csv/output.csv'\n",
    "dst = DATA_INPUT + 'to_csv/' + DFNAME + '.csv'\n",
    "shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/benjamin/Folders_Python/Cyber/data/input_pcaps/to_csv/' + DFNAME + '.csv'\n",
    "\n",
    "with open(file=filename, encoding='utf-8') as f:\n",
    "    df_raw = pd.read_csv(\n",
    "        f,\n",
    "        header=0,               # using first row as columns names. they are exported by tshark -E header=y\n",
    "        on_bad_lines='warn'     # if a line does not have the right length, skip it but warn me\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.number</th>\n",
       "      <th>eth.src</th>\n",
       "      <th>eth.dst</th>\n",
       "      <th>ip.src_host</th>\n",
       "      <th>ip.dst_host</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>ip.hdr_len</th>\n",
       "      <th>ip.ttl</th>\n",
       "      <th>tcp.srcport</th>\n",
       "      <th>tcp.dstport</th>\n",
       "      <th>tcp.stream</th>\n",
       "      <th>tcp.len</th>\n",
       "      <th>tcp.seq</th>\n",
       "      <th>tcp.ack</th>\n",
       "      <th>tcp.hdr_len</th>\n",
       "      <th>tcp.time_relative</th>\n",
       "      <th>tcp.time_delta</th>\n",
       "      <th>tcp.flags</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40:61:86:9a:f1:f5</td>\n",
       "      <td>00:1a:8c:15:f9:80</td>\n",
       "      <td>192.168.3.131</td>\n",
       "      <td>72.14.213.138</td>\n",
       "      <td>983</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>57011</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0x0018</td>\n",
       "      <td>2011-01-25 18:52:22.484409+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>00:1a:8c:15:f9:80</td>\n",
       "      <td>40:61:86:9a:f1:f5</td>\n",
       "      <td>72.14.213.138</td>\n",
       "      <td>192.168.3.131</td>\n",
       "      <td>426</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>57011</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>20</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>0x0018</td>\n",
       "      <td>2011-01-25 18:52:22.514250+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40:61:86:9a:f1:f5</td>\n",
       "      <td>00:1a:8c:15:f9:80</td>\n",
       "      <td>192.168.3.131</td>\n",
       "      <td>72.14.213.102</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>55950</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0x0002</td>\n",
       "      <td>2011-01-25 18:52:22.708292+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40:61:86:9a:f1:f5</td>\n",
       "      <td>00:1a:8c:15:f9:80</td>\n",
       "      <td>192.168.3.131</td>\n",
       "      <td>72.14.213.138</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>57011</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>944</td>\n",
       "      <td>387</td>\n",
       "      <td>20</td>\n",
       "      <td>0.229423</td>\n",
       "      <td>0.199582</td>\n",
       "      <td>0x0010</td>\n",
       "      <td>2011-01-25 18:52:22.713832+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>00:1a:8c:15:f9:80</td>\n",
       "      <td>40:61:86:9a:f1:f5</td>\n",
       "      <td>72.14.213.102</td>\n",
       "      <td>192.168.3.131</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>55950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>0x0012</td>\n",
       "      <td>2011-01-25 18:52:22.727058+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13703</th>\n",
       "      <td>13704</td>\n",
       "      <td>08:00:27:cc:3f:1b</td>\n",
       "      <td>52:54:00:12:35:02</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>65.55.15.244</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>2537</td>\n",
       "      <td>5480</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>5039</td>\n",
       "      <td>5738</td>\n",
       "      <td>20</td>\n",
       "      <td>71.195375</td>\n",
       "      <td>66.560501</td>\n",
       "      <td>0x0014</td>\n",
       "      <td>2011-01-25 18:57:20.768701+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13704</th>\n",
       "      <td>13705</td>\n",
       "      <td>08:00:27:cc:3f:1b</td>\n",
       "      <td>52:54:00:12:35:02</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>207.46.105.186</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>2540</td>\n",
       "      <td>5480</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>398</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>70.606228</td>\n",
       "      <td>5.540471</td>\n",
       "      <td>0x0014</td>\n",
       "      <td>2011-01-25 18:57:20.768769+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13705</th>\n",
       "      <td>13706</td>\n",
       "      <td>08:00:27:cc:3f:1b</td>\n",
       "      <td>52:54:00:12:35:02</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>96.17.8.49</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>2547</td>\n",
       "      <td>5480</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>8189</td>\n",
       "      <td>20</td>\n",
       "      <td>64.405045</td>\n",
       "      <td>64.259982</td>\n",
       "      <td>0x0014</td>\n",
       "      <td>2011-01-25 18:57:20.768861+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13706</th>\n",
       "      <td>13707</td>\n",
       "      <td>08:00:27:cc:3f:1b</td>\n",
       "      <td>52:54:00:12:35:02</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>91.103.140.2</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>2546</td>\n",
       "      <td>5480</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>270</td>\n",
       "      <td>20</td>\n",
       "      <td>64.884164</td>\n",
       "      <td>64.357688</td>\n",
       "      <td>0x0014</td>\n",
       "      <td>2011-01-25 18:57:20.768911+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13707</th>\n",
       "      <td>13708</td>\n",
       "      <td>08:00:27:cc:3f:1b</td>\n",
       "      <td>52:54:00:12:35:02</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>65.54.167.27</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>2548</td>\n",
       "      <td>5480</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>42479</td>\n",
       "      <td>20</td>\n",
       "      <td>62.477118</td>\n",
       "      <td>61.854118</td>\n",
       "      <td>0x0014</td>\n",
       "      <td>2011-01-25 18:57:20.768972+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13708 rows Ã 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame.number            eth.src            eth.dst    ip.src_host  \\\n",
       "0                 1  40:61:86:9a:f1:f5  00:1a:8c:15:f9:80  192.168.3.131   \n",
       "1                 2  00:1a:8c:15:f9:80  40:61:86:9a:f1:f5  72.14.213.138   \n",
       "2                 3  40:61:86:9a:f1:f5  00:1a:8c:15:f9:80  192.168.3.131   \n",
       "3                 4  40:61:86:9a:f1:f5  00:1a:8c:15:f9:80  192.168.3.131   \n",
       "4                 5  00:1a:8c:15:f9:80  40:61:86:9a:f1:f5  72.14.213.102   \n",
       "...             ...                ...                ...            ...   \n",
       "13703         13704  08:00:27:cc:3f:1b  52:54:00:12:35:02      10.0.2.15   \n",
       "13704         13705  08:00:27:cc:3f:1b  52:54:00:12:35:02      10.0.2.15   \n",
       "13705         13706  08:00:27:cc:3f:1b  52:54:00:12:35:02      10.0.2.15   \n",
       "13706         13707  08:00:27:cc:3f:1b  52:54:00:12:35:02      10.0.2.15   \n",
       "13707         13708  08:00:27:cc:3f:1b  52:54:00:12:35:02      10.0.2.15   \n",
       "\n",
       "          ip.dst_host  ip.len  ip.hdr_len  ip.ttl  tcp.srcport  tcp.dstport  \\\n",
       "0       72.14.213.138     983          20     128        57011           80   \n",
       "1       192.168.3.131     426          20      52           80        57011   \n",
       "2       72.14.213.102      52          20     128        55950           80   \n",
       "3       72.14.213.138      40          20     128        57011           80   \n",
       "4       192.168.3.131      52          20      52           80        55950   \n",
       "...               ...     ...         ...     ...          ...          ...   \n",
       "13703    65.55.15.244      40          20     128         2537         5480   \n",
       "13704  207.46.105.186      40          20     128         2540         5480   \n",
       "13705      96.17.8.49      40          20     128         2547         5480   \n",
       "13706    91.103.140.2      40          20     128         2546         5480   \n",
       "13707    65.54.167.27      40          20     128         2548         5480   \n",
       "\n",
       "       tcp.stream  tcp.len  tcp.seq  tcp.ack  tcp.hdr_len  tcp.time_relative  \\\n",
       "0               0      943        1        1           20           0.000000   \n",
       "1               0      386        1      944           20           0.029841   \n",
       "2               1        0        0        0           32           0.000000   \n",
       "3               0        0      944      387           20           0.229423   \n",
       "4               1        0        0        1           32           0.018766   \n",
       "...           ...      ...      ...      ...          ...                ...   \n",
       "13703         407        0     5039     5738           20          71.195375   \n",
       "13704         409        0      398       93           20          70.606228   \n",
       "13705         419        0      496     8189           20          64.405045   \n",
       "13706         417        0      525      270           20          64.884164   \n",
       "13707         420        0     1902    42479           20          62.477118   \n",
       "\n",
       "       tcp.time_delta tcp.flags                         DateTime  \n",
       "0            0.000000    0x0018 2011-01-25 18:52:22.484409+00:00  \n",
       "1            0.029841    0x0018 2011-01-25 18:52:22.514250+00:00  \n",
       "2            0.000000    0x0002 2011-01-25 18:52:22.708292+00:00  \n",
       "3            0.199582    0x0010 2011-01-25 18:52:22.713832+00:00  \n",
       "4            0.018766    0x0012 2011-01-25 18:52:22.727058+00:00  \n",
       "...               ...       ...                              ...  \n",
       "13703       66.560501    0x0014 2011-01-25 18:57:20.768701+00:00  \n",
       "13704        5.540471    0x0014 2011-01-25 18:57:20.768769+00:00  \n",
       "13705       64.259982    0x0014 2011-01-25 18:57:20.768861+00:00  \n",
       "13706       64.357688    0x0014 2011-01-25 18:57:20.768911+00:00  \n",
       "13707       61.854118    0x0014 2011-01-25 18:57:20.768972+00:00  \n",
       "\n",
       "[13708 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['DateTime'] = pd.to_datetime(df_raw['_ws.col.Date'], utc=True)\n",
    "\n",
    "df_raw.drop(columns=['_ws.col.Date'], inplace=True)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labellisation by Suricata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURICATA_EVE_LOG = DATA_OUTPUT + '/eve.json'\n",
    "\n",
    "# delete existing eve.json file if it exists, suricata would append data otherwise\n",
    "if os.path.isfile(SURICATA_EVE_LOG):\n",
    "    os.remove(SURICATA_EVE_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Suricata and generate the log file in the EVE.JSON output file\n",
    "cli=\"suricata -r \" + PCAPFILE + \" tcp \" + \" -l \" + DATA_OUTPUT + \" -k none\"  # discard invalid checksum alert\n",
    "\n",
    "%time exit_code = os.system(cli)\n",
    "\n",
    "if exit_code == 0:\n",
    "    logger.info('Executed successfully *.pcap to EVE.json translation with suricata')\n",
    "else:\n",
    "    logger.error('Error while using suricata to analyse from *.pcap to EVE.json')\n",
    "    raise NameError('Error while using suricata to analyse from *.pcap to EVE.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas provides a useful method â json_normalize â for normalizing nested JSON fields into dataframe. Resulting columns use dot notation to signify nested objects, similar to how Elasticsearch does it\n",
    "\n",
    "with open (SURICATA_EVE_LOG) as packets:\n",
    "    df_log = pd.json_normalize(\n",
    "        [json.loads(packet) for packet in packets],\n",
    "        max_level=1\n",
    "    )\n",
    "    \n",
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log['event_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(df_log[df_log['event_type'] == 'anomaly'])} anomalie(s)\")\n",
    "print(f\"{len(df_log[df_log['event_type'] == 'alert'])} alert(e)\")\n",
    "\n",
    "n_alerts = len(df_log[df_log['event_type'] == 'alert'])\n",
    "n_anomalies = len(df_log[df_log['event_type'] == 'anomaly'])\n",
    "\n",
    "logger.info(f'Found {n_alerts} alert(s) in *.json')\n",
    "logger.info(f'Found {n_anomalies} anomalie(s) in *.json')\n",
    "\n",
    "if n_alerts == 0:\n",
    "    msg = 'no alert found in suricata file'\n",
    "    logger.error(msg)\n",
    "    raise NameError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract anomalies out of the whole log, put it in a specific dataframe\n",
    "df_interest = df_log[df_log['event_type']=='alert']\n",
    "\n",
    "# post-process : convert timestamp to UTC-datetime, set index\n",
    "df_interest['DateTime'] = pd.to_datetime(df_interest['timestamp'],utc=True)\n",
    "df_interest.drop(columns=['timestamp'], inplace=True)\n",
    "df_interest.set_index(keys='DateTime', drop=False, inplace=True)\n",
    "\n",
    "df_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interest['alert.category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idÃ©e : \n",
    "# 1. parcourir les DateTime du sous-ensemble des anomalies dÃ©tectÃ©es par Suricata\n",
    "# 2. regarder s'il y a un paquet avec ce timestamp exact dans l'extraction tshark\n",
    "# 3. si oui : flagger y=1 le paquet dans la df tshark (et rajouter les champs d'explication)\n",
    "# 4. si non : logger une anomalie orpheline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df = df.set_index(keys='DateTime', drop=False)\n",
    "df['y'] = 0  # set number of anomalies per *.pcap packet\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_alerts = 0\n",
    "\n",
    "for anomaly_datetime in df_interest.index:\n",
    "    df.loc[anomaly_datetime, 'y'] = df.loc[anomaly_datetime, 'y'] + 1\n",
    "    ctr_alerts += 1\n",
    "    \n",
    "print(f'comptÃ© {ctr_alerts} alerte(s)')\n",
    "print(f\"assigned {df['y'].sum()} alerte(s)\")\n",
    "\n",
    "df['y'].unique()  # Il peut y avoir plusieurs alertes par paquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export final en *.csv\n",
    "\n",
    "DF_OUTPUT_DIR = '/home/benjamin/Folders_Python/Cyber/data/dataframes/'\n",
    "DF_FILENAME = DF_OUTPUT_DIR + 'df_' + DFNAME + '.csv'\n",
    "\n",
    "with open(DF_FILENAME, 'w') as f:\n",
    "    df.to_csv(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
